{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installation succeeded 2025-10-02 19:34:18.265847\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started new cluster \"dhub.63d6bd36a4ba4536a5fd22112399e68e\"\n",
      "Connected to cluster: \"dhub.63d6bd36a4ba4536a5fd22112399e68e\"\n",
      "Dask Dashboard: https://jupyter.chloris-geospatial.com/services/dask-gateway/clusters/dhub.63d6bd36a4ba4536a5fd22112399e68e/status\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-02 22:06:01,945 - distributed.client - ERROR - Failed to reconnect to scheduler after 30.00 seconds, closing client\n"
     ]
    }
   ],
   "source": [
    "n = 50  # Number of workers. You're going to want 100 if you need to run mask_and_rechunk\n",
    "cores = 2  # Number of cpu cores per worker\n",
    "ram = 15  # GB of ram per worker\n",
    "\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\"format_bytes is deprecated and will be removed in a future release. Please use dask.utils.format_bytes instead.\",\n",
    ")\n",
    "warnings.filterwarnings(\"ignore\", message=\"coroutine 'rpc.close_rpc' was never awaited\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"Enable tracemalloc to get the object allocation traceback\")\n",
    "\n",
    "gateway = Gateway()\n",
    "clusters = list(gateway.list_clusters(\"running\"))\n",
    "for cluster in clusters:\n",
    "    print(f'''Stopping other cluster: \"{cluster.name}\"''')\n",
    "    gateway.stop_cluster(cluster.name)\n",
    "\n",
    "options = gateway.cluster_options()\n",
    "options.worker_cores = cores\n",
    "options.worker_memory = ram\n",
    "options.image = \"Jupyter AGBD\"\n",
    "\n",
    "cluster = gateway.new_cluster(cluster_options=options, shutdown_on_close=False)\n",
    "print(f'''Started new cluster \"{cluster.name}\"''')\n",
    "\n",
    "# scaling options\n",
    "# manual scaling, the recommended method\n",
    "cluster.scale(n)\n",
    "\n",
    "client = cluster.get_client(set_as_default=True)\n",
    "print(\n",
    "    f\"\"\"Connected to cluster: \"{cluster.name}\"\\nDask Dashboard: {'https://jupyter.chloris-geospatial.com' + cluster.dashboard_link}\"\"\"\n",
    ")\n",
    "\n",
    "# Sync selected chloris_agbd branch to dask workers.\n",
    "gitlab_token = toml.load(os.path.join(Path.home(), \".gitlab_token\"))\n",
    "sync_source_to_dask_workers(client, gitlab_token, branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://jupyter.chloris-geospatial.com/services/dask-gateway/clusters/dhub.63d6bd36a4ba4536a5fd22112399e68e/status\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:asyncio:Task exception was never retrieved\n",
      "future: <Task finished name='Task-2518' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2199> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2208, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "ERROR:asyncio:Task exception was never retrieved\n",
      "future: <Task finished name='Task-2483' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2199> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2208, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "ERROR:asyncio:Task exception was never retrieved\n",
      "future: <Task finished name='Task-2506' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2199> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2208, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "ERROR:asyncio:Task exception was never retrieved\n",
      "future: <Task finished name='Task-2507' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2199> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2208, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "ERROR:asyncio:Task exception was never retrieved\n",
      "future: <Task finished name='Task-2514' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2199> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2208, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "ERROR:asyncio:Task exception was never retrieved\n",
      "future: <Task finished name='Task-2508' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2199> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2208, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n"
     ]
    }
   ],
   "source": [
    "from dask_gateway import Gateway\n",
    "\n",
    "\n",
    "gateway = Gateway()\n",
    "cluster = gateway.connect(gateway.list_clusters()[0].name)\n",
    "client = cluster.get_client()\n",
    "\n",
    "print(f\"https://jupyter.chloris-geospatial.com{client.dashboard_link}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import rioxarray as rxr\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from chloris_agbd.aws.s3 import get_s3fs_filesystem\n",
    "from chloris_agbd.backends.zarr import to_zarr\n",
    "from dask import delayed, compute\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_chm_1m_zarr(site_name:str,\n",
    "\t\tchunk_size:int = 1000,\n",
    "\t\toverwrite:bool = True,\n",
    "\t\tjoin_type:str = 'inner',\n",
    "        chm_path:str = 's3://chloris-data-us-west-2/projects/NEON/CHM/'):\n",
    "\n",
    "\ts3fs = get_s3fs_filesystem()\n",
    "\n",
    "\t# Get the files in the CHM dir\n",
    "\tflist = s3fs.ls(chm_path,detail = True)\n",
    "\tflist = [f['Key'] for f in flist if f['type'] == 'file']\n",
    "\n",
    "\t# Get the ones for this site \n",
    "\tsite_files = [f\"s3://{x}\" for x in flist if site_name in x and x.endswith('.tif')]\n",
    "\tsite_years = [int(x.split('_')[1]) for x in site_files]\n",
    "\n",
    "\tchm_list = [] \n",
    "\tfor fname, year in zip(site_files, site_years):\n",
    "\n",
    "\t\tchm_i = rxr.open_rasterio(fname, mask_and_scale=True, chunks = {'x':chunk_size,'y':chunk_size}).squeeze()\n",
    "\t\tchm_i = chm_i.expand_dims(year = [year])\n",
    "\t\tchm_list.append(chm_i)\n",
    "\n",
    "\tchm_da = xr.concat(chm_list, dim='year',join = join_type)\n",
    "\tchm_da = chm_da.chunk({'x': chunk_size, 'y': chunk_size, 'year': -1})\n",
    "\tchm_da = chm_da.rename('canopy_height').astype('float32').to_dataset()\n",
    "\n",
    "\tchm_fname = f\"{chm_path.rstrip('/')}/zarrs/{site_name}_chm_1m.zarr\"\n",
    "\n",
    "\tto_zarr(chm_fname, chm_da, overwrite=overwrite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "site_names = ['DELA','LENO','TALL','BONA','DEJU','HEAL','SRER','SJER','SOAP',\n",
    "              'TEAK','CPER','NIWO','RMNP','DSNY','OSBS','JERC','PUUM','KONZ',\n",
    "              'UKFS','SERC','HARV','UNDE','BART','JORN','DCFS','NOGP','WOOD',\n",
    "              'GUAN','LAJA','GRSM','ORNL','CLBJ','MOAB','ONAQ','BLAN','MLBS',\n",
    "              'SCBI','ABBY','WREF','STEI','TREE','YELL']\n",
    "\n",
    "# Wrap your function call with dask.delayed\n",
    "tasks = []\n",
    "for site_name in site_names:\n",
    "    task = delayed(make_chm_1m_zarr)(site_name)\n",
    "    tasks.append(task)\n",
    "\n",
    "# Trigger parallel execution on the cluster\n",
    "compute(*tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
